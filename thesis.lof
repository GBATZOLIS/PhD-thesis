\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces From left to right: ideal dependencies in the $i^{th}$ autoregressive component. Dual-Glow modeling assumption \cite {Dual-Glow}; information is exchanged only between latent spaces having the same dimension. Our modeling assumption; we retain the dependencies between $L_i$ and the latent spaces of lower dimension.}}{33}{figure.caption.56}%
\contentsline {figure}{\numberline {2.2}{\ignorespaces Left: unconditional normalizing flow architecture used to encode conditioning and conditioned images, denoted by $Y_n = Y$ and $W_n = W$ respectively, into a sequence of hierarchical latent variables. Right: design of the conditional transformation $G_{i}^\theta $ that models the $i^{th}$ autoregressive component. The index of the flow $i$ is omitted in both the transformed latent variable $Z_j$ and the intermediate latent variables $Z_j^{\prime }$ for simplicity.}}{34}{figure.caption.57}%
\contentsline {figure}{\numberline {2.3}{\ignorespaces Illustration of a multi-scale diffusion model with three scales. Inspired by multi-scale normalizing flows, this approach diffuses different parts of the image tensor (transformed into multi-level Haar coefficients) at varying speeds. High-frequency detail coefficients diffuse progressively faster, with $d_1$ diffusing faster than $d_2$, $d_2$ faster than $d_3$, and so on, ensuring that all coefficients reach the same (very low) signal-to-noise ratio (SNR) at their respective terminal diffusion times: $t = 0.25, 0.5, 0.75$, and $1.0$, respectively. The low-frequency approximation coefficients $a_3$ diffuse the slowest, completing their diffusion at $t = 1.0$. The multi-scale structure reduces the dimensionality of the diffusing tensor at each scale, enabling faster computation. Separate neural networks $S_1, S_2, S_3, S_4$ approximate the score functions at different intervals, leveraging the reduced dimensionality of the intermediate distributions. This hierarchical design mirrors the structure of multi-scale normalizing flows, improving training and sampling efficiency while maintaining high image generation quality.}}{35}{figure.caption.59}%
\contentsline {figure}{\numberline {2.4}{\ignorespaces Results from our conditional multi-speed diffusive estimator.}}{36}{figure.caption.60}%
\contentsline {figure}{\numberline {2.5}{\ignorespaces (Left) Visualization of the score field near the data manifold. (Right) Visualisation of the estimation of the manifold dimension using the trained diffusion model.}}{37}{figure.caption.62}%
\contentsline {figure}{\numberline {2.6}{\ignorespaces Comparison of original and reconstructed images on the FFHQ dataset using our ScoreVAE framework. The left panel presents the original images from the FFHQ dataset, while the right panel displays the corresponding reconstructions generated by ScoreVAE. The results highlight the effectiveness of ScoreVAE in capturing intricate details and preserving high fidelity, overcoming the limitations of traditional VAE models.}}{39}{figure.caption.64}%
\contentsline {figure}{\numberline {2.7}{\ignorespaces Approximate data manifolds learned by the Riemannian autoencoder generated by score-based pullback Riemannian geometry for three datasets. The orange surfaces represent the manifolds learned by the model, while the blue points correspond to the training data. Each manifold provides a convincing low-dimensional representation of the data, isometric to its respective latent space. }}{41}{figure.caption.66}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces From left to right: ideal dependencies in the $i^{th}$ autoregressive component. Dual-Glow modeling assumption \cite {Dual-Glow}; information is exchanged only between latent spaces having the same dimension. Our modeling assumption; we retain the dependencies between $L_i$ and the latent spaces of lower dimension.}}{54}{figure.caption.68}%
\contentsline {figure}{\numberline {3.2}{\ignorespaces Left: unconditional normalizing flow architecture used to encode conditioning and conditioned images, denoted by $Y_n = Y$ and $W_n = W$ respectively, into a sequence of hierarchical latent variables. Right: design of the conditional transformation $G_{i}^\theta $ that models the $i^{th}$ autoregressive component. The index of the flow $i$ is omitted in both the transformed latent variable $Z_j$ and the intermediate latent variables $Z_j^{\prime }$ for simplicity.}}{56}{figure.caption.69}%
\contentsline {figure}{\numberline {3.3}{\ignorespaces 10 super-resolved versions of the LR image in decreasing conditional log-likelihood order.}}{61}{figure.caption.70}%
\contentsline {figure}{\numberline {3.4}{\ignorespaces Qualitative comparison of Dual-Glow+ and CAFLOW.}}{62}{figure.caption.72}%
\contentsline {figure}{\numberline {3.5}{\ignorespaces Qualitative evaluation on FFHQ 4x super-resolution of 16x16 resolution images.}}{63}{figure.caption.75}%
\contentsline {figure}{\numberline {3.6}{\ignorespaces Qualitative evaluation: Four colorizations proposed by CAFLOW, CINN and ColorGAN for three test images. ColorGAN generates unrealistically diverse colorizations with significant color artifacts (for example a yellow region on a white wall). CINN generates more realistic, less diverse colorizations with fewer pronounced color artifacts compared to ColorGAN, which is reflected in the improved FID score. Finally, CAFLOW generates even more realistic and less diverse colorizations than CINN with even rarer color artifacts, which is more representative of the data distribution according to the FID score.}}{64}{figure.caption.76}%
\contentsline {figure}{\numberline {3.7}{\ignorespaces Different inpaintings proposed by CAFLOW with $\tau =0.5$. Ground truth on the right.}}{65}{figure.caption.78}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces Results from our conditional multi-speed diffusive estimator.}}{68}{figure.caption.81}%
\contentsline {figure}{\numberline {4.2}{\ignorespaces Model with three scales. $d_1$ reaches the target SNR at $t=0.25$ and does not diffuse further. The remaining part of tensor continues the diffusion. The diffusion procedure is continued as implied until $a_3$ reaches the target SNR at time $t=1$. We use four neural networks $S_1, S_2, S_3, S_4$ to approximate the score function in the intermediate diffusion intervals, because the dimensionality of the diffusing tensor decreases every time some part of the tensor reaches the target SNR.}}{75}{figure.caption.84}%
\contentsline {figure}{\numberline {4.3}{\ignorespaces Sources of error for different estimators}}{79}{figure.caption.90}%
\contentsline {figure}{\numberline {4.4}{\ignorespaces Diversity of five different CMDE reconstructions for a given masked image.}}{83}{figure.caption.92}%
\contentsline {figure}{\numberline {4.5}{\ignorespaces Inpainting results.}}{85}{figure.caption.95}%
\contentsline {figure}{\numberline {4.6}{\ignorespaces Super-resolution results.}}{86}{figure.caption.97}%
\contentsline {figure}{\numberline {4.7}{\ignorespaces Edge to image translation results.}}{87}{figure.caption.99}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {5.1}{\ignorespaces The data manifold (in blue) and the neural approximation of the score field $\nabla _\textbf {x} \ln p_{t_0}(\textbf {x})$ obtained from a diffusion model. Near the manifold the score field is perpendicular to the manifold surface.}}{91}{figure.caption.100}%
\contentsline {figure}{\numberline {5.2}{\ignorespaces To estimate the manifold's dimension at point \(\mathbf {x}_0\) (red dot), we sample \(K\) nearby points \(\mathbf {x}_{\epsilon }^{(i)}\) (blue dots) and use the trained diffusion model to evaluate the score function \(s_\theta (\mathbf {x}_\epsilon ^{(i)}, \epsilon )\) at these perturbed points. We assemble these vectors into a matrix and perform Singular Value Decomposition (SVD). The number of (almost) zero singular values reveals the manifold's dimension.}}{91}{figure.caption.100}%
\contentsline {figure}{\numberline {5.3}{\ignorespaces Singular values for the scores of $k$-sphere for $k=10, 50$. In both cases around $k$ singular values almost vanish, clearly indicating the dimensionality of the manifold. Each line shows a score spectrum at different $\textbf {x}_0^{(j)}$.}}{99}{figure.caption.101}%
\contentsline {figure}{\numberline {5.4}{\ignorespaces Auto-encoder reconstruction error on MNIST for different latent space dimensions. Vertical lines mark different estimations of intrinsic dimension.}}{101}{figure.caption.102}%
\contentsline {figure}{\numberline {5.5}{\ignorespaces MNIST score spectra that yielded the highest estimated dimension for each digit}}{101}{figure.caption.103}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {6.1}{\ignorespaces Graphical overview of our method. The time-dependent encoder network $e_\phi $ induces the encoder distribution $q_\phi ( \textbf {z} | \textbf {x}_t, t) \approx p_t( \textbf {z} | \textbf {x}_t)$. The data $\textbf {x}_0$ is encoded with the encoder into a latent vector $\textbf {z}$ by sampling $q_\phi ( \textbf {z} | \textbf {x}_0, 0)$. Then the reconstruction $\hat {\textbf {x}}_0$ is obtained by running the conditional reverse diffusion process using the approximate conditional data score $s_{\theta , \phi }(\textbf {x}_t, \textbf {z},t) \approx \nabla _{\textbf {x}_t} \ln {p(\textbf {x}_t | \textbf {z})}$. The model $s_{\theta , \phi }(\textbf {x}_t, \textbf {z},t)$ is obtained by adding the score of unconditional diffusion model $s_\theta (\textbf {x}_t,t) \approx \nabla _{\textbf {x}_t} \ln {p(\textbf {x}_t)} $ and the score of the encoder distribution $ \nabla _{\textbf {x}_t} \ln q_\phi ( \textbf {z} | \textbf {x}_t, t) \approx \nabla _{\textbf {x}_t} \ln {p(\textbf {z} | \textbf {x}_t )} $. The latter can be computed via automatic differentiation with respect to the input $\textbf {x}_t$.}}{111}{figure.caption.108}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {7.1}{\ignorespaces Approximate data manifolds learned by the Riemannian autoencoder generated by score-based pullback Riemannian geometry for three datasets. The orange surfaces represent the manifolds learned by the model, while the blue points correspond to the training data. Each manifold provides a convincing low-dimensional representation of the data, isometric to its respective latent space. }}{118}{figure.caption.112}%
\contentsline {figure}{\numberline {7.2}{\ignorespaces Score-based pullback Riemannian geometry (proposed) from a toy probability density.}}{119}{figure.caption.113}%
\contentsline {figure}{\numberline {7.3}{\ignorespaces Comparison of geodesics computed using different methods on the river dataset. The geodesics generated by the proposed method have least artifacts, which is in line with our expectations from Table~\ref {tab:geodesic-variation-errors}.}}{128}{figure.caption.115}%
\contentsline {figure}{\numberline {7.4}{\ignorespaces Approximate data manifold learned by the Riemannian autoencoder for the Sinusoid(1, 100) dataset. The orange curves depict the manifold learned by the model, while the blue points show the training data. We visualize three different combinations of the ambient dimensions. }}{130}{figure.caption.117}%
\contentsline {figure}{\numberline {7.5}{\ignorespaces Learned variances and reconstruction errors for the Hemisphere(5,20) and Sinusoid(5,20) datasets. The plots in the left column show the learned variances in decreasing order for each dataset, while the right column illustrates the average $\ell ^2$ reconstruction error as a function of the number of latent dimensions used. The reconstruction errors are evaluated for three variance-based orders of the latent dimensions: the \textbf {blue line} (circular markers) represents adding dimensions in decreasing order of variance, the \textbf {green line} (square markers) for increasing variance, and the \textbf {red line} (diamond markers) for a random order.\vspace {-2em} }}{132}{figure.caption.119}%
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {A.1}{\ignorespaces Image super-resolution on the FFHQ dataset. Left: LR bicubicly upsampled. Right: HR image. Middle: 10 super-resolved versions in decreasing conditional log-likelihood order from left to right. We sampled 20 super-resolved images for each LR image and we present the 10 images with the highest conditional log-likelihood. We used sampling temperature $\tau =0.5$.}}{161}{figure.caption.121}%
\contentsline {figure}{\numberline {A.2}{\ignorespaces Image super-resolution on the FFHQ dataset. Left: LR bicubicly upsampled. Right: HR image. Middle: 10 super-resolved versions in decreasing conditional log-likelihood order from left to right. We sampled 20 super-resolved images for each LR image and we present the 10 images with the highest conditional log-likelihood. We used sampling temperature $\tau =0.55$.}}{162}{figure.caption.122}%
\contentsline {figure}{\numberline {A.3}{\ignorespaces Image inpainting on the CelebA dataset. Left: Masked image. Right: Ground truth. Middle: 10 inpainted versions in decreasing conditional log-likelihood order from left to right. We sampled 30 inpainted images for each masked image and we present the 10 images with the highest conditional log-likelihood. We used sampling temperature $\tau =0.5$.}}{163}{figure.caption.123}%
\contentsline {figure}{\numberline {A.4}{\ignorespaces Image inpainting on the CelebA dataset. Left: Masked image. Right: Ground truth. Middle: 10 inpainted versions in decreasing conditional log-likelihood order from left to right. We sampled 30 inpainted images for each masked image and we present the 10 images with the highest conditional log-likelihood. We used sampling temperature $\tau =0.5$.}}{164}{figure.caption.124}%
\contentsline {figure}{\numberline {A.5}{\ignorespaces Image colorization on the LSUN BEDROOM dataset. Left: Grayscale image. Right: Ground truth. Middle: 10 colorized versions in decreasing conditional log-likelihood order from left to right. We sampled 25 colorized images for each greyscale image and we present the 10 images with the highest conditional log-likelihood. We used sampling temperature $\tau =0.85$.}}{165}{figure.caption.125}%
\contentsline {figure}{\numberline {A.6}{\ignorespaces Image colorization on the LSUN BEDROOM dataset. Left: Grayscale image. Right: Ground truth. Middle: 10 colorized versions in decreasing conditional log-likelihood order from left to right. We sampled 25 colorized images for each greyscale image and we present the 10 images with the highest conditional log-likelihood. We used sampling temperature $\tau =0.85$.}}{166}{figure.caption.126}%
\contentsline {figure}{\numberline {A.7}{\ignorespaces Image colorization on the FFHQ dataset. Left: Grayscale image. Right: Ground truth. Middle: 10 colorized versions in decreasing conditional log-likelihood order from left to right. We sampled 25 colorized images for each greyscale image and we present the 10 images with the highest conditional log-likelihood. We used sampling temperature $\tau =0.7$.}}{167}{figure.caption.127}%
\contentsline {figure}{\numberline {A.8}{\ignorespaces Image colorization on the FFHQ dataset. Left: Grayscale image. Right: Ground truth. Middle: 10 colorized versions in decreasing conditional log-likelihood order from left to right. We sampled 25 colorized images for each greyscale image and we present the 10 images with the highest conditional log-likelihood. We used sampling temperature $\tau =0.7$.}}{168}{figure.caption.128}%
\contentsline {figure}{\numberline {A.9}{\ignorespaces Sketch to image synthesis on the edges2shoes dataset \cite {isola2017image}. Left: Sketch. Right: Ground truth. Middle: 6 samples taken with sampling temperature $\tau =0.8$.}}{169}{figure.caption.129}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {B.1}{\ignorespaces Vanilla - CelebA-HQ $128\times 128$}}{185}{figure.caption.131}%
\contentsline {figure}{\numberline {B.2}{\ignorespaces Multiscale - CelebA-HQ $128\times 128$}}{186}{figure.caption.132}%
\contentsline {figure}{\numberline {B.3}{\ignorespaces Multiscale + - CelebA-HQ $128\times 128$}}{187}{figure.caption.133}%
\contentsline {figure}{\numberline {B.4}{\ignorespaces Extended super-resolution results.}}{188}{figure.caption.134}%
\contentsline {figure}{\numberline {B.5}{\ignorespaces Extended inpainting results.}}{189}{figure.caption.135}%
\contentsline {figure}{\numberline {B.6}{\ignorespaces Extended edge to shoe synthesis results.}}{190}{figure.caption.136}%
\contentsline {figure}{\numberline {B.7}{\ignorespaces Extended edge to shoe synthesis results.}}{190}{figure.caption.137}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {C.1}{\ignorespaces Caption without FN}}{196}{figure.caption.140}%
\contentsline {figure}{\numberline {C.2}{\ignorespaces Nine samples from Squares image manifolds of dimensions 10, 20 and 100 (from left to right).}}{205}{figure.caption.147}%
\contentsline {figure}{\numberline {C.3}{\ignorespaces Nine samples from Gaussian blob image manifolds of dimensions 10, 20 and 100 (from left to right).}}{205}{figure.caption.147}%
\contentsline {figure}{\numberline {C.4}{\ignorespaces Projection of the spaghetti line on the first three dimensions.}}{206}{figure.caption.148}%
\contentsline {figure}{\numberline {C.5}{\ignorespaces Score spectrum of the spaghetti line. The last singular value clearly vanishes indicating that the intrinsic dimensionality of the manifold is equal to one.}}{206}{figure.caption.148}%
\contentsline {figure}{\numberline {C.6}{\ignorespaces Score spectrum for the union of $k$-spheres ($k_1=10, k_2=30$). The separated drops in the spectra clearly show that the data comes form the union of two manifolds of different dimensions.}}{206}{figure.caption.149}%
\contentsline {figure}{\numberline {C.7}{\ignorespaces The histogram of estimated dimensions for the union of $k$-spheres ($k_1=10, k_2=30$). The counts are taken over estimates $\hat {k}(\textbf {x}_0^{(i)})$ at different points $\textbf {x}_0^{(i)}$.}}{206}{figure.caption.149}%
\contentsline {figure}{\numberline {C.8}{\ignorespaces Score spectra and histogram of estimated dimension based on the score spectrum of the Squares image manifold of dimensions 10, 20 and 100.}}{207}{figure.caption.150}%
\contentsline {figure}{\numberline {C.9}{\ignorespaces Score spectra and histogram of estimated dimension based on the score spectrum of the Gaussian blobs image manifold of dimensions 10, 20 and 100.}}{207}{figure.caption.150}%
\contentsline {figure}{\numberline {C.10}{\ignorespaces MNIST score spectra for all digits}}{208}{figure.caption.151}%
\contentsline {figure}{\numberline {C.11}{\ignorespaces Score spectra for noise corrupted score model on 25-sphere.}}{210}{figure.caption.152}%
\contentsline {figure}{\numberline {C.12}{\ignorespaces Dimensionality estimates for uniform and non-uniform distributions on a 10-sphere. On the right, we present histograms showing how many points $\textbf {x}_0^{(j)}$ result in a given $\hat {k}(\textbf {x}_0^{(j)})$. Taking $\hat {k} = \max _j \hat {k}(\textbf {x}_0^{(j)})$ allows for robust estimation for moderate values of the concentration parameter $\alpha $.}}{212}{figure.caption.154}%
\contentsline {figure}{\numberline {C.13}{\ignorespaces Score spectra for score models on 25-sphere trained on noisy manifold data.}}{213}{figure.caption.155}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {D.1}{\ignorespaces Examples where the $L_2$-distance is not a (semantically) meaningful distance between images. In the left column, a reference image from ImageNet \citep {imagenet} is shown. In the middle column, a slight alteration is applied, whose result a human observer would consider to be very close to the reference image. In the right column, another image from the ImageNet data set is displayed, which to the human observer is very different from the reference image, but which has a lower $L_2$-distance to the reference image than the altered image. The numbers above the images indicate the $L_2$-distance to the reference image. Figure taken from \cite {stanczuk2021wasserstein}.}}{217}{figure.caption.156}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {E.1}{\ignorespaces Visualization of the datasets used in our manifold mapping experiments.}}{225}{figure.caption.161}%
